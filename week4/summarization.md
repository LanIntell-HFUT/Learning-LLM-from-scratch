# Week4 Summarization
## 作业1的第2、3部分
* 包括书中和作业中有关Transformer架构和GPT模型实现的代码
    * 实现了高效的多头注意力机制
    * 实现了RoPE编码
* 介绍了作业的基准测试程序

## 课程汇报部分
### 问题
* 课程是否有LLM的使用方面的内容 没有
* 今天的内容过于底层了
* 以后写代码时可以考虑写一个性能测试的部分，分析代码效率

### 总结
* 介绍了GPU和CPU的区别，GPU的组成部分；
* 介绍了线程、线程束、线程块在GPU中的组织；
* 介绍了内存访问优化，突发区域；针对存储顺序（行存储、列存储）进行行访问和列访问，减少时间开销；
* 还介绍了一个有意思的小练习，通过分块+内存对齐+填充的组合，让GPU访问矩阵数据时能充分利用内存的突发传输机制，最大化带宽利用率，从而提升矩阵运算的性能；
* 介绍了编写高性能代码的两个要素：基准测试和性能分析；基准测试只能在粗粒度上进行代码效率分析，进一步需要进行性能分析，查看CUDA内核调用的细节、每一步的具体步骤和运行时间。
* 用生动形象的示例介绍了性能分析工具和性能分析过程，以及打印loss值语句对程序运行的性能影响。